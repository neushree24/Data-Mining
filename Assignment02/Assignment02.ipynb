{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COSC 526 - Assignment 01\n",
    "### January 29, 2021\n",
    "---\n",
    "\n",
    "In this notebook, we provide you with basic functions for completing the assignment.  *You will need to modify existing code and write new code to find a solution*.  Each member of the group must upload their own work to their personal GitHub repository, which we set up during the first class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Tasks:\n",
    "\n",
    "This set of practical tasks is to be completed during the first class.\n",
    "\n",
    "**Definitions:**\n",
    "- **GitHub:** web-based hosting service for version control used to distribute and collect assignments as well as other class materials (e.g., slides, code, and datasets)\n",
    "- **Git:** software used by GitHub\n",
    "\n",
    "**Practical Tasks:** \n",
    "- Create your own GitHub account\n",
    "- Submit your GitHub username to the Google form: https://forms.gle/CKugke8Dzqjm9tQ89\n",
    "- Install Git on your laptop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This Assignment is due (pushed to your personal class GitHub repository) at the start of the second class.**\n",
    "\n",
    "# Problem 1\n",
    "\n",
    "In this problem we explore reading in and parsing [delimiter-separated values](https://en.wikipedia.org/wiki/Delimiter-separated_values) stored in files.  We start with [comma-separated values](https://en.wikipedia.org/wiki/Comma-separated_values) and then move on to [tab-separated values](https://en.wikipedia.org/wiki/Tab-separated_values).\n",
    "\n",
    "### Problem 1a: Comma-Separated Values (CSV)\n",
    "\n",
    "From [Wikipedia](https://en.wikipedia.org/wiki/Comma-separated_values): In computing, a comma-separated values (CSV) file stores tabular data (numbers and text) in plain text. Each line of the file is a data record. Each record consists of one or more fields, separated by commas. The use of the comma as a field separator is the source of the name for this file format.\n",
    "\n",
    "If you were to consider the CSV file as a matrix, each line would represent a row and each comma would represent a column.  In the provided CSV file, the first row consists of a header that \"names\" each column.  In this problem, ...\n",
    "\n",
    "- Count (and print) the number of rows of data (header is excluded) in the csv file\n",
    "- Count (and print) the number of columns of data in the csv file\n",
    "- Calculate (and print) the average of the values that are in the \"age\" column\n",
    "  - You can assume each age in the file is an integer, but the average should be calculated as a float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows of data: 8\n",
      "Number of cols: 3\n",
      "Average Age: 70.875\n"
     ]
    }
   ],
   "source": [
    "def parse_delimited_file(filename, delimiter=\",\"):\n",
    "    # Open and read in all lines of the file\n",
    "    # (I do not recommend readlines for LARGE files)\n",
    "    # `open`: ref [1]\n",
    "    # `readlines`: ref [2]\n",
    "    with open(filename, 'r', encoding='utf8') as dsvfile:\n",
    "        lines = dsvfile.readlines()\n",
    "    \n",
    "    \n",
    "    # Strip off the newline from the end of each line\n",
    "    # Using list comprehension is the recommended pythonic way to iterate through lists\n",
    "    # HINT: refs [3,4]\n",
    "\n",
    "    \n",
    "    # Split each line based on the delimiter (which, in this case, is the comma)\n",
    "    # HINT: ref [5]\n",
    "\n",
    "        list1 = []\n",
    "        for line in lines:\n",
    "# \n",
    "            list1.append(line.rstrip('\\n'))\n",
    "            \n",
    "        list2 = []\n",
    "            \n",
    "        for line1 in list1:\n",
    "            list2.append(line1.split(delimiter))\n",
    "            \n",
    "    \n",
    "    # Separate the header from the data\n",
    "    # HINT: ref [6]\n",
    "#         print(list)\n",
    "        header = list2[0]\n",
    "       \n",
    "        data = list2[slice(1,None)]\n",
    "    \n",
    "    # Find \"age\" within the header\n",
    "    # (i.e., calculating the column index for \"age\")\n",
    "    # HINT: ref [7]\n",
    "\n",
    "        age_colidx = header.index('age')\n",
    " \n",
    "\n",
    "    # Calculate the number of data rows and columns\n",
    "    # HINT: [8]\n",
    "        num_data_rows = 0\n",
    "        num_data_cols = 0\n",
    "    \n",
    "    \n",
    "        num_data_rows = len(data)\n",
    "        num_data_cols = len(header)\n",
    "    # Sum the \"age\" values\n",
    "    # HINT: ref [9]\n",
    "        age_list = []\n",
    "        for member in data:\n",
    "            age_list.append(int(member[age_colidx]))\n",
    "        \n",
    "    # Calculate the average age\n",
    "        ave_age = 0\n",
    "        ave_age = sum(age_list)/len(data)\n",
    "    \n",
    "    # Print the results\n",
    "    # `format`: ref [10]\n",
    "        print(\"Number of rows of data: {}\".format(num_data_rows))\n",
    "        print(\"Number of cols: {}\".format(num_data_cols))\n",
    "        print(\"Average Age: {}\".format(ave_age))\n",
    "    \n",
    "# Parse the provided csv file\n",
    "parse_delimited_file('data.csv',',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Ouput:**\n",
    "```\n",
    "Number of rows of data: 8\n",
    "Number of cols: 3\n",
    "Average Age: 70.875\n",
    "```\n",
    "**References:**\n",
    "- [1: open](https://docs.python.org/3.6/library/functions.html#open)\n",
    "- [2: readlines](https://docs.python.org/3.6/library/codecs.html#codecs.StreamReader.readlines)\n",
    "- [3: list comprehension](https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions)\n",
    "- [4: rstrip](https://docs.python.org/3.6/library/stdtypes.html#str.rstrip)\n",
    "- [5: split](https://docs.python.org/3.6/library/stdtypes.html#str.split)\n",
    "- [6: splice](https://docs.python.org/3.6/glossary.html#term-slice)\n",
    "- [7: \"more on lists\"](https://docs.python.org/3.6/tutorial/datastructures.html#more-on-lists)\n",
    "- [8: len](https://docs.python.org/3.6/library/functions.html#len)\n",
    "- [9: int](https://docs.python.org/3.6/library/functions.html#int)\n",
    "- [10: format](https://docs.python.org/3.6/library/stdtypes.html#str.format)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1b: Tab-Separated Values (TSV)\n",
    "\n",
    "From [Wikipedia](https://en.wikipedia.org/wiki/Tab-separated_values): A tab-separated values (TSV) file is a simple text format for storing data in a tabular structure, e.g., database table or spreadsheet data, and a way of exchanging information between databases. Each record in the table is one line of the text file. Each field value of a record is separated from the next by a tab character. The TSV format is thus a type of the more general delimiter-separated values format.\n",
    "\n",
    "In this problem, repeat the analyses performed in the prevous problem, but for the provided tab-delimited file.\n",
    "\n",
    "**NOTE:** the order of the columns has changed in this file.  If you hardcoded the position of the \"age\" column, think about how you can generalize the `parse_delimited_file` function to work for any delimited file with an \"age\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows of data: 8\n",
      "Number of cols: 3\n",
      "Average Age: 70.875\n"
     ]
    }
   ],
   "source": [
    "# Further reading on optional arguments, like \"delimiter\": http://www.diveintopython.net/power_of_introspection/optional_arguments.html\n",
    "parse_delimited_file('data.tsv', delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Ouput:**\n",
    "```\n",
    "Number of rows of data: 8\n",
    "Number of cols: 3\n",
    "Average Age: 70.875\n",
    "```\n",
    "---\n",
    "\n",
    "# Problem 2\n",
    "\n",
    "If you opened the `data.csv` file, you may have noticed some non-english letters in the names column.  These characters are represented using [Unicode](https://en.wikipedia.org/wiki/Unicode), a standard for representing many different types and forms of text.  Python 3 [natively supports](https://docs.python.org/3/howto/unicode.html) Unicode, but many tools do not.  Some tools require text to be formatted with [ASCII](https://en.wikipedia.org/wiki/ASCII).\n",
    "\n",
    "Convert the unicode-formatted names into ascii-formated names, and save the names out to a file named `data-ascii.txt` (one name per line).  We have provided you with a [tranliteration dictionary](https://german.stackexchange.com/questions/4992/conversion-table-for-diacritics-e-g-%C3%BC-%E2%86%92-ue) that maps several common unicode characters to their ascii transliteration.  Use this dictionary to convert the unicode strings to ascii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Richard Phillips Feynman\n",
      "Shin'ichiro Tomonaga\n",
      "Julian Schwinger\n",
      "Rudolf Ludwig Moessbauer\n",
      "Erwin Schroedinger\n",
      "Paul Dirac\n",
      "Maria Sklodowska-Curie\n",
      "Pierre Curie\n"
     ]
    }
   ],
   "source": [
    "translit_dict = {\n",
    "    \"ä\" : \"ae\",\n",
    "    \"ö\" : \"oe\",\n",
    "    \"ü\" : \"ue\",\n",
    "    \"Ä\" : \"Ae\",\n",
    "    \"Ö\" : \"Oe\",\n",
    "    \"Ü\" : \"Ue\", \n",
    "    \"ł\" : \"l\",\n",
    "    \"ō\" : \"o\",\n",
    "}\n",
    "\n",
    "with open(\"data.csv\", 'r', encoding='utf8') as csvfile:\n",
    "    lines = csvfile.readlines()\n",
    "\n",
    "    \n",
    "\n",
    "list1 = []\n",
    "for line in lines:\n",
    "# \n",
    "    list1.append(line.rstrip('\\n'))\n",
    "            \n",
    "list2 = []\n",
    "            \n",
    "for line1 in list1:\n",
    "    list2.append(line1.split(','))\n",
    "            \n",
    "    \n",
    "    # Separate the header from the data\n",
    "\n",
    "header = list2[0]\n",
    "       \n",
    "data = list2[slice(1,None)]\n",
    "    \n",
    "    # Find \"age\" within the header\n",
    "    # (i.e., calculating the column index for \"age\")\n",
    "age_colidx = header.index('age')\n",
    "\n",
    "\n",
    "\n",
    "unicode_names = []\n",
    "\n",
    "for member in data:\n",
    "    unicode_names.append(member[name])\n",
    "\n",
    "# print(unicode_names)\n",
    "\n",
    "# Iterate over the names\n",
    "translit_names = []\n",
    "\n",
    "for unicode_name in unicode_names:\n",
    "    for key in translit_dict:\n",
    "        unicode_name = unicode_name.replace(key, translit_dict[key])\n",
    "    \n",
    "    translit_names.append(unicode_name)\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    " # print(translit_names)\n",
    "\n",
    "# Write out the names to a file named \"data-ascii.txt\"\n",
    "# HINT: ref [2]\n",
    " \n",
    "with open('data-ascii.txt', 'w') as ascii_file:\n",
    "    for line in translit_names:\n",
    "        ascii_file.writelines(line + '\\n')\n",
    "    \n",
    "ascii_file.close()\n",
    "     \n",
    "     \n",
    "\n",
    "\n",
    "#Verify that the names were converted and written out correctly\n",
    "with open(\"data-ascii.txt\", 'r') as infile:\n",
    "    for line in infile:\n",
    "        print(line.rstrip('\\n'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```\n",
    "Richard Phillips Feynman\n",
    "Shin'ichiro Tomonaga\n",
    "Julian Schwinger\n",
    "Rudolf Ludwig Moessbauer\n",
    "Erwin Schroedinger\n",
    "Paul Dirac\n",
    "Maria Sklodowska-Curie\n",
    "Pierre Curie\n",
    "```\n",
    "\n",
    "**References:**\n",
    "- [1: replace](https://docs.python.org/3.6/library/stdtypes.html#str.replace)\n",
    "- [2: file object methods](https://docs.python.org/3/tutorial/inputoutput.html#methods-of-file-objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Free-Form Questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Your solutions for Problems 1 & 2 probably share a lot of code in common. You might even have copied-and-pasted from Problem 1 into Problem 2. Refactor parse_delimited_file to be useful in both problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_delimited_file(filename, delimiter):\n",
    " \n",
    "    with open(filename, 'r', encoding='utf8') as dsvfile:\n",
    "        lines = dsvfile.readlines()\n",
    "    \n",
    "        list1 = []\n",
    "        for line in lines:\n",
    "# \n",
    "            list1.append(line.rstrip('\\n'))\n",
    "            \n",
    "        list2 = []\n",
    "            \n",
    "        for line1 in list1:\n",
    "            list2.append(line1.split(delimiter))\n",
    "            \n",
    "    \n",
    "    # Separate the header from the data\n",
    "    # HINT: ref [6]\n",
    "#         print(list)\n",
    "        header = list2[0]\n",
    "       \n",
    "        data = list2[slice(1,None)]\n",
    "    \n",
    "    # Find \"age\" within the header\n",
    "  \n",
    "        age_colidx = header.index('age')\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. Are there any pre-built Python packages that could help you solve these problems? If yes, refactor your solutions to use those packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add here your code \n",
    "import csv\n",
    "\n",
    "with open(\"data.csv\", 'r', encoding='utf8') as csvfile:\n",
    "    csv_reader = csv.reader(csvfile, delimiter=',')\n",
    "    header = next(csv_reader)\n",
    "    data = [row for row in csv_reader]\n",
    "    \n",
    "    age_idx = header.index('age')\n",
    "    \n",
    "#problem1\n",
    "  \n",
    "    num_data_rows = 0\n",
    "    num_data_cols = 0\n",
    "    \n",
    "    \n",
    "    num_data_rows = len(data)\n",
    "    num_data_cols = len(header)\n",
    "  \n",
    "    age_list = []\n",
    "    for member in data:\n",
    "        age_list.append(int(member[age_colidx]))\n",
    "        \n",
    "    # Calculate the average age\n",
    "    ave_age = 0\n",
    "    ave_age = sum(age_list)/len(data)\n",
    "        \n",
    "    \n",
    "#problem2    \n",
    "\n",
    "    translit_dict = {\n",
    "    \"ä\" : \"ae\",\n",
    "    \"ö\" : \"oe\",\n",
    "    \"ü\" : \"ue\",\n",
    "    \"Ä\" : \"Ae\",\n",
    "    \"Ö\" : \"Oe\",\n",
    "    \"Ü\" : \"Ue\", \n",
    "    \"ł\" : \"l\",\n",
    "    \"ō\" : \"o\",\n",
    "}\n",
    "        \n",
    "    unicode_names = []\n",
    "\n",
    "for member in data:\n",
    "    unicode_names.append(member[name])\n",
    "\n",
    "translit_names = []\n",
    "\n",
    "for unicode_name in unicode_names:\n",
    "    for key in translit_dict:\n",
    "        unicode_name = unicode_name.replace(key, translit_dict[key])\n",
    "    \n",
    "    translit_names.append(unicode_name)\n",
    "    \n",
    "with open('data-ascii.txt', 'w') as ascii_file:\n",
    "    for line in translit_names:\n",
    "        ascii_file.writelines(line + '\\n')\n",
    "    \n",
    "ascii_file.close()\n",
    "     \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. Tell us about your experience (for each point below provide a couple of sentences).\n",
    "- Describe the challenges you faced in addressing these tasks and how you overcame these challenges.\n",
    "- Did you work with other students on this assignment? If yes, how did you help them? How did they help you?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I needed to go back and revise the related things otherwise it was fine. Yes, I worked with a friend in the same class. We discussed sometimes when we got issues.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live Chat: The History of Big Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intel's Genevieve Bell shows that we have been dealing with big data for millennia, and that approaching big data problems with the right frame of reference is the key addressing many of the problems we face today from the keynote of Supercomputing 2013: https://youtu.be/CNoi-XqwJnA\n",
    "\n",
    "List three key concepts you learned by watching the video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three key concepts discussed in the video are:\n",
    "1.Collecting data(facts)\n",
    "2.Analysis and visualization (framework)\n",
    "3.Extracting value (algorithm)\n",
    "\n",
    "Speaker gave the illustration of each point using the Doomsday book. Also, the concept of data was explained by giving examples of mobile media in India. The concept of visualization was discussed based on the map of cholera outburst in England. And, the concept of the algorithm was illustrated by giving the example of digital platforms like Amazon, Netflix, and google.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live Chat: What we learned from 5 million books!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Live Chat:\n",
    "Jean-Baptiste Michel and Erez Lieberman Aiden tell us about “What we learned from 5 million books”\n",
    "https://www.ted.com/talks/jean_baptiste_michel_erez_lieberman_aiden_what_we_learned_from_5_million_books\n",
    "\n",
    "Answer these questions related to the talk:\n",
    "- What is the take-away of this talk? Summarize it in up to 3 sentences.\n",
    "- What are metadata?\n",
    "- What is a n-gram?\n",
    "- What is the suppression index? \n",
    "- What is culturomics? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Digitization of the books is a great way of getting access to the books right away. The reader can use computational methods to go through the books and also because of digitization many books can be retrieved and preserved. They shorted out the digitization process using the concept of n-grams.\n",
    "\n",
    "2.Metadata is the information about the things like in case of the books who was the author, when and where it was published.\n",
    "\n",
    "3.The number of words that appeared in a particular sentence, for instance, \"A gleam of happiness.\" is a sentence of four words so it’s a four-gram.\n",
    "\n",
    "4.Supression index is the ratio of observed and expected outputs.\n",
    "\n",
    "5.Culturomics is the process of studying the human culture by the massive data collection and analysis.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Reading Assignment: MapReduce: Simpli\u0002ed Data Processing on Large Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the three-pass approch to read the paper: Jeffrey Dean and Sanjay Ghemawat (2004) MapReduce: Simpli\u0002ed Data Processing on Large Clusters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
